---

title: "Rethinking Algorithm Ethics: Reflections on Mike Ananny’s \"Toward an Ethics of Algorithms\""
published: 2025-02-25
description: 'What happens when algorithms don’t just show the world—but shape how we think within it?'
image: ''
tags: [Ethics]
category:  'Articles'
draft: false
seriesCategory: "Mindscapes"
seriesCategoryDescription: "Fragments of thought, memory, and imagination—tracing the shifting landscapes of the mind. Through personal musings and reflections, each piece explores the subtle connections between being, time, and meaning"
series: "Time Echoes"
seriesDescription: "Exploring how lives are shaped across time—through the stories we remember, the systems we build, and the futures we envision. This series gathers fragments of thought where technology meets humanity"
---

:::important
The views and opinions expressed in this article are entirely personal and do not reflect the official policy or position of any affiliated organizations or institutions.
:::

In today’s digital world, it’s tempting to think of algorithms as merely technical—silent engines driving content, decisions, and recommendations. But as Mike Ananny argues in his article [Toward an Ethics of Algorithms: Convening, Observation, Probability, and Timeliness](https://journals.sagepub.com/doi/10.1177/0162243915606523), algorithms are anything but neutral. They are cultural and political artifacts—deeply shaped by human intentions, institutional goals, and social assumptions.

Ananny presents a compelling ethical framework for understanding how algorithms influence public life, structured around three core dimensions: **Convening Constituents**, **Governing Probability**, and **Structuring Time**. As I read through the article, these concepts didn’t just stay theoretical—they resonated with experiences I’ve had online and challenged me to rethink how I understand agency, autonomy, and fairness in algorithmic systems.

## Convening Constituents: Being Placed, Not Just Participating

Ananny begins with the idea that algorithms "convene"—they bring people together not by explicit choice, but by automated categorization. This isn’t about community as we traditionally know it. It’s about data-driven sorting, where past behaviors, preferences, and interactions are used to define who belongs where.

This struck me because it mirrors the way I’ve seen platforms like Xiaohongshu or TikTok create insular content bubbles. The more I engage with certain content, the narrower my feed becomes—feeding me more of what I’ve already seen, and less of what I haven’t. It’s efficient, yes. But it also raises a deeper concern: **What kinds of communities are being silently built for us?** And who gets excluded?

These algorithmically formed groups aren’t neutral. They reflect value judgments—who is relevant, who is profitable, who is visible. They don’t just mirror society; they shape it. And in doing so, they can amplify divisions, reinforce stereotypes, and limit exposure to diverse perspectives. This has made me more conscious of the spaces I inhabit online, and how little control I might actually have over who or what I encounter.

## Governing Probability: Personalization or Predetermination?

The second dimension, governing probability, explores how algorithms don’t just respond to users—they predict and influence their actions. This predictive power sounds useful at first, until we realize how deeply it shapes the options we believe we have.

Ananny’s discussion reminded me of a situation I once encountered on Taobao: two users searching for the same item received vastly different prices—one over 80 yuan, the other just over 8. This isn’t a bug. It’s the system working *as intended*. Each user is profiled, segmented, and served content tailored to what the algorithm thinks they’re willing to pay.

This example perfectly encapsulates a subtle but powerful shift: **our perceived autonomy is often algorithmically curated**. We’re nudged toward outcomes that align with what platforms value—whether that’s engagement, spending, or behavioral conformity. Over time, this can erode the very freedom of choice that personalization claims to offer.

Reading this, I began to question how much of my own digital behavior is genuinely self-directed. If algorithms increasingly guide what we see, buy, or believe, then where is the line between helpful prediction and covert manipulation? Ananny doesn’t offer a simple answer—but his framing makes the ethical tension impossible to ignore.

## Structuring Time: The Politics of What Comes First

Of all Ananny’s dimensions, the idea of “structuring time” resonated most deeply with me. Algorithms decide not only *what* we see, but *when* we see it—and that order matters. In social media feeds or search engine results, content is ranked by engagement, recency, or other opaque signals, subtly influencing our attention, emotions, and memory.

I’ve noticed how easily important but less sensational content gets buried under viral trends. Platforms optimize for attention, not for nuance. In this sense, algorithms don’t just distort time—they **reshape the public sense of history, urgency, and relevance**.

This realization was unsettling. I had always assumed that the internet, by storing everything, preserves everything. But if what’s visible is constantly shifting based on algorithmic logic, then our digital memory is fragile—subject to decay, disappearance, or manipulation. In that light, algorithmic control over time feels like a kind of editorial power, determining what narratives survive.

## Navigating Ethics in a System Built for Efficiency

Ananny doesn’t stop at diagnosis. He invites us to think through these issues using three classic ethical frameworks: **deontological ethics**, which focuses on rules and duties; **consequentialist ethics**, which weighs outcomes; and **virtue ethics**, which considers the character and values of those involved in technological development.

This multi-perspective lens is especially helpful when grappling with emerging technologies like gene editing, facial recognition, or AI-generated content. What I appreciated is that Ananny doesn’t push one ethical view as superior—instead, he encourages us to recognize their tensions, overlaps, and blind spots.

Yet as I reflected on this, one lingering question remained: **How can these ethical principles actually be embedded into real-world systems?** In an industry dominated by speed, growth, and profitability, moral reasoning often feels like a luxury. Where does it fit in a sprint-based development cycle? Who is responsible for holding the line?

I don’t have easy answers. But I believe we need broader systems of accountability—not just within companies, but through regulation, education, and public discourse. More importantly, we need users (myself included) to become more **algorithmically literate**. Only then can we begin to question the choices being made on our behalf.

## Toward a More Reflective Tech Future

Ananny’s article is not a call to reject algorithms—it’s a call to see them more clearly. They are not invisible or inevitable. They are designed. And with that design comes responsibility.

What I took from this reading is the importance of slowing down. In a culture obsessed with optimization, reflection itself becomes an act of resistance. Ethics may seem like friction, something that slows innovation. But maybe, in some cases, that’s exactly what we need.

We need to ask better questions about who benefits, who gets harmed, and whose voices are missing. Because in the end, the future we build with technology will reflect the values we allow to guide it.

And if we don’t choose those values carefully, algorithms will choose them for us.


